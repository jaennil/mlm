"""
Gradio application for beverage package classification.

This application uses an ONNX model to classify images of beverage packages
into three categories: cans, paper cups, and plastic bottles.
"""

import gradio as gr
import onnxruntime as ort
import numpy as np
from PIL import Image
import albumentations as A
from albumentations.pytorch import ToTensorV2
from pathlib import Path

# Configuration
APP_DIR = Path(__file__).parent
ONNX_PATH = APP_DIR / "model.onnx"
CLASS_NAMES = ["–ñ–µ—Å—Ç—è–Ω–∞—è –±–∞–Ω–∫–∞", "–ö–∞—Ä—Ç–æ–Ω–Ω—ã–π —Å—Ç–∞–∫–∞–Ω", "–ü–ª–∞—Å—Ç–∏–∫–æ–≤–∞—è –±—É—Ç—ã–ª–∫–∞"]

# Image preprocessing (same as validation transform)
transform = A.Compose([
    A.Resize(224, 224),
    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
    ToTensorV2(),
])

# Load ONNX model
if not ONNX_PATH.exists():
    raise FileNotFoundError(
        f"ONNX model not found at {ONNX_PATH}. "
        "Please train the model first using: python train.py --config best"
    )

session = ort.InferenceSession(str(ONNX_PATH))


def predict(img: Image.Image):
    """
    Predict the class of a beverage package image.
    
    Args:
        img: PIL Image
        
    Returns:
        str: Prediction result with class name and confidence score
    """
    
    try:
        # Preprocess image
        x = transform(image=np.array(img))["image"].numpy()
        x = np.expand_dims(x, 0)
        
        # Run inference
        pred = session.run(None, {"input": x})[0]
        
        # Get prediction
        idx = np.argmax(pred)
        confidence = pred[0][idx]
        
        # Format result
        result = f"**{CLASS_NAMES[idx]}**\n\n–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {confidence:.2%}"
        
        # Add probabilities for all classes
        result += "\n\n### –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –≤—Å–µ—Ö –∫–ª–∞—Å—Å–æ–≤:"
        for _, (class_name, prob) in enumerate(zip(CLASS_NAMES, pred[0])):
            result += f"\n- {class_name}: {prob:.2%}"
        
        return result
        
    except Exception as e:
        return f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {str(e)}"


# Create Gradio interface
demo = gr.Interface(
    fn=predict,
    inputs=gr.Image(type="pil", label="–ó–∞–≥—Ä—É–∑–∏—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —É–ø–∞–∫–æ–≤–∫–∏ –Ω–∞–ø–∏—Ç–∫–∞"),
    outputs=gr.Markdown(label="–†–µ–∑—É–ª—å—Ç–∞—Ç –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏"),
    title="ü•´ –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä —É–ø–∞–∫–æ–≤–æ–∫ –Ω–∞–ø–∏—Ç–∫–æ–≤",
    description="""
    –ó–∞–≥—Ä—É–∑–∏—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —É–ø–∞–∫–æ–≤–∫–∏ –Ω–∞–ø–∏—Ç–∫–∞, –∏ –º–æ–¥–µ–ª—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç –µ—ë —Ç–∏–ø:
    - ü•´ **–ñ–µ—Å—Ç—è–Ω–∞—è –±–∞–Ω–∫–∞** (–º–µ—Ç–∞–ª–ª–∏—á–µ—Å–∫–∏–µ –±–∞–Ω–∫–∏ –¥–ª—è –Ω–∞–ø–∏—Ç–∫–æ–≤)
    - ‚òï **–ö–∞—Ä—Ç–æ–Ω–Ω—ã–π —Å—Ç–∞–∫–∞–Ω** (–±—É–º–∞–∂–Ω—ã–µ —Å—Ç–∞–∫–∞–Ω—á–∏–∫–∏ –¥–ª—è –∫–æ—Ñ–µ/—á–∞—è)
    - üçº **–ü–ª–∞—Å—Ç–∏–∫–æ–≤–∞—è –±—É—Ç—ã–ª–∫–∞** (–ø–ª–∞—Å—Ç–∏–∫–æ–≤—ã–µ –±—É—Ç—ã–ª–∫–∏ –¥–ª—è –≤–æ–¥—ã/—Å–æ–∫–æ–≤)
    """,
    examples=[
        # Add paths to example images if available
    ],
    article="""
    ### –û –ø—Ä–æ–µ–∫—Ç–µ
    
    –ú–æ–¥–µ–ª—å –æ–±—É—á–µ–Ω–∞ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º transfer learning –Ω–∞ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–µ ConvNeXt Tiny.
    –î–æ—Å—Ç–∏–≥–Ω—É—Ç–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–æ–π –≤—ã–±–æ—Ä–∫–µ: **100%**.
    
    **–¢–µ—Ö–Ω–æ–ª–æ–≥–∏–∏:**
    - PyTorch + timm –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
    - ONNX –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞
    - Gradio –¥–ª—è –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞
    
    **–ü—Ä–∏–º–µ—á–∞–Ω–∏–µ:** –õ—É—á—à–µ –≤—Å–µ–≥–æ —Ä–∞–±–æ—Ç–∞–µ—Ç —Å —á–µ—Ç–∫–∏–º–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏ —É–ø–∞–∫–æ–≤–æ–∫ –Ω–∞ –æ–¥–Ω–æ—Ä–æ–¥–Ω–æ–º —Ñ–æ–Ω–µ.
    """,
    theme=gr.themes.Soft(),
    allow_flagging="never"
)

if __name__ == "__main__":
    demo.launch(
        share=False,
        server_name="0.0.0.0",
        server_port=7860
    )
